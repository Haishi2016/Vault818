{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple DNN Network to teach computers Rock, Paper, Scissors, Lizard, Spock\n",
    "\n",
    "This notebook captures all steps to build a simple DNN network to teach the computer rules to play the Rock, Paper, Scissors, Lizard, Spock game:\n",
    "\n",
    "As Sheldon in Big Bang Theory explains, \"Scissors cuts paper, paper covers rock, rock rushes lizard, lizard poisons Spock, Spock smashes scissors, scissors decapitates lizard, lizard eats paper, paper disproves Spock, Spock vaporizes rock, and as it ways has, rock crushes scissors.\"\n",
    "\n",
    "## Inputs and outputs\n",
    "\n",
    "The inputs to the network is a one-hot array representing one of the possible throws, in the order of $[rock, paper, scissors, lizard, Spock]$. For example, $[1,0,0,0,0]$ represents Rock. The outputs of the network is also a one-hot array representing a winning throw that beats the input. For example, for a \"Rock\" input, the output can be either $[0,1,0,0,0]$ (paper) or $[0,0,0,0,1]$ (Spock).\n",
    "\n",
    "## Training set and overfitting\n",
    "\n",
    "We need a very tiny training set to cover all possilbe input-output combinations. We won't care about overfitting in this case as we know there's a perfect solution in this case.\n",
    "\n",
    "## Network topology\n",
    "\n",
    "We'll use a DNN with 1 hidden layer. This is probably unnecessary, given the simplcity of the problem. However, it's a good exercise to walk through the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the training set is so small we can simply supply it as an array\n",
    "X = [\n",
    "    [[1],[0],[0]],\n",
    "    [[0],[1],[0]],\n",
    "    [[0],[0],[1]]\n",
    "]\n",
    "y = [\n",
    "    [[0],[1],[0]],\n",
    "    [[0],[0],[1]],\n",
    "    [[1],[0],[1]]\n",
    "]\n",
    "\n",
    "# we want to shuffle the previous arrays, but to keep the results repeatable, we'll use the same random seed\n",
    "np.random.seed(42)\n",
    "rnd_idx = np.random.permutation(len(X)) # we need to make sure both X and y are shuffled in the same way, hence generting indexes first\n",
    "X=np.take(X, rnd_idx, axis = 0).astype(np.float)\n",
    "y=np.take(y, rnd_idx, axis = 0).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll set apart 2 elements as the test set\n",
    "X_train, y_train = X, y\n",
    "X_valid, y_valid = X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(3,1)),\n",
    "    tf.keras.layers.Dense(3, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='relu'),\n",
    "    tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 33ms/sample - loss: 1.0986 - acc: 0.5556\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 667us/sample - loss: 1.0986 - acc: 0.5556\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 1.0986 - acc: 0.5556\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 667us/sample - loss: 1.0986 - acc: 0.5556\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 664us/sample - loss: 1.0986 - acc: 0.5556\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 667us/sample - loss: 1.0986 - acc: 0.5556\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 347us/sample - loss: 1.0986 - acc: 0.5556\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 1.0986 - acc: 0.5556\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.0986 - acc: 0.5556\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 1.0986 - acc: 0.5556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b8fdcc6160>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 1.0986 - acc: 0.5556\n",
      "\n",
      "Test accuracy: 0.5555556\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_valid,  y_valid, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.33333334, 0.33333334, 0.33333334],\n",
       "        [0.33333334, 0.33333334, 0.33333334],\n",
       "        [0.33333334, 0.33333334, 0.33333334]],\n",
       "\n",
       "       [[0.33333334, 0.33333334, 0.33333334],\n",
       "        [0.33333334, 0.33333334, 0.33333334],\n",
       "        [0.33333334, 0.33333334, 0.33333334]],\n",
       "\n",
       "       [[0.33333334, 0.33333334, 0.33333334],\n",
       "        [0.33333334, 0.33333334, 0.33333334],\n",
       "        [0.33333334, 0.33333334, 0.33333334]]], dtype=float32)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
